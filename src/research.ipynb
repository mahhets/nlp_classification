{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import nltk\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score, confusion_matrix\n",
    "\n",
    "\n",
    "from nlp_classification.environment_reference import EnvironmentReference\n",
    "from nlp_classification.fill_functions import FeatureSelector, Cleaner, Lemmatizer\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Необходимо классифицировать сообщения на предмет того, из какого чата они были взяты.\n",
    "Датасет представляет собой сообщения участников двух публичных чатов:\n",
    "- Чат по Python (label=0)\n",
    "- Чат по Data Science (label=1)\n",
    "\n",
    "\n",
    "### Задачи:\n",
    "1. Сделать предобработку текстов\n",
    "2. Предложить модель классификации, метрики.\n",
    "3. Объяснить их выбор (достоинства/недостатки).\n",
    "4. Сделать выводы по работе модели(ей) (достоинства/недостатки),\n",
    "а также проблемы, с которыми вы или ваша модель столкнулась."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Загрузка данных"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12404 entries, 0 to 12403\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    12404 non-null  object\n",
      " 1   label   12404 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 193.9+ KB\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "data = pd.read_csv(os.getenv(EnvironmentReference.RESEARCH_DATA_PATH))\n",
    "data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Посмотрим на баланс класса"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "group_data = data.groupby('label').describe()\n",
    "python_norm = round(data['label'].value_counts(normalize=True)[0],2)\n",
    "ds_norm = round(data['label'].value_counts(normalize=True)[1],2)\n",
    "\n",
    "plt.bar(f'Python - {python_norm}',group_data['text']['count'][0],\n",
    "        label = 'Python', color = 'blue')\n",
    "plt.bar(f'DataScience - {ds_norm}',group_data['text']['count'][1],\n",
    "        label = 'DataScience', color = 'green')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Выборка имеет хороший баланс лейблов. На самом деле в подобных задачах(векторизации) плохая\n",
    "балансировка не является чем-то неразрешимым.\n",
    "\n",
    "### Преобработка текста\n",
    "\n",
    "Для предобработки текста были реализованы классы Cleaner(очистка текста) и Lemmatizer(лемматизация).\n",
    "Из библиотеки nltk были подгружены стоп-слова для дальнейшего удаления их из текста,\n",
    "они не несут смысловой нагрузки и лишь вносят шум + нагружают модель."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mahh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Подгрузим стоп-слова\n",
    "# Далее в классе Cleaner будут подгружены именно русские стоп-слова\n",
    "nltk.download('stopwords')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Создадим пайплайны для классификаторов:\n",
    "1. MultinomialNB\n",
    "2. SGDClassifier\n",
    "3. LogisticRegression\n",
    "4. RandomForestClassifier\n",
    "5. CatBoostClassifier\n",
    "6. KNeighborsClassifier\n",
    "\n",
    "P.S. CatBoostClassifier очень долго обучается, к тому-же без тонких настроек он дает самую плохую метрику из всех\n",
    "представленных классификаторов. Мой ноутбук будет очень долго подбирать параметры по Grid, вынужден отказаться\n",
    "в силу быстродействия выполнения. При этом я не отрицаю что возможно при должных настройках он покажет высокие результаты"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "classifier_1 = Pipeline([('selector', FeatureSelector(column='text')),\n",
    "                         ('cleaner', Cleaner(column='text')),\n",
    "                         ('lemma', Lemmatizer(column='text')),\n",
    "                         ('tfidf', TfidfVectorizer(sublinear_tf=True,\n",
    "                                                   strip_accents='unicode',\n",
    "                                                   analyzer='word', # аналитика по словам\n",
    "                                                   token_pattern=r'\\w{1,}', # выдергиваем разделители\n",
    "                                                # длина ngram(ngram - смотрим на последовательности слов длиной 1 с шагом 1)\n",
    "                                                   ngram_range=(1, 1),\n",
    "                                                   max_features=10000)),\n",
    "                         ('clf', MultinomialNB())])\n",
    "\n",
    "classifier_2 = Pipeline([('selector', FeatureSelector(column='text')),\n",
    "                         ('cleaner', Cleaner(column='text')),\n",
    "                         ('lemma', Lemmatizer(column='text')),\n",
    "                         ('tfidf', TfidfVectorizer(sublinear_tf=True,\n",
    "                                                            strip_accents='unicode',\n",
    "                                                            analyzer='word',\n",
    "                                                            token_pattern=r'\\w{1,}',\n",
    "                                                            ngram_range=(1, 1),\n",
    "                                                            max_features=10000)),\n",
    "                         ('clf', SGDClassifier(loss='modified_huber', penalty='l2', alpha=1e-3))])\n",
    "\n",
    "\n",
    "classifier_3 = Pipeline([('selector', FeatureSelector(column='text')),\n",
    "                         ('cleaner', Cleaner(column='text')),\n",
    "                         ('lemma', Lemmatizer(column='text')),\n",
    "                         ('tfidf', TfidfVectorizer(sublinear_tf=True,\n",
    "                                                            strip_accents='unicode',\n",
    "                                                            analyzer='word',\n",
    "                                                            token_pattern=r'\\w{1,}',\n",
    "                                                            ngram_range=(1, 1),\n",
    "                                                            max_features=10000)),\n",
    "                         ('clf', LogisticRegression(penalty='l2',C=2))])\n",
    "\n",
    "classifier_4 = Pipeline([('selector', FeatureSelector(column='text')),\n",
    "                         ('cleaner', Cleaner(column='text')),\n",
    "                         ('lemma', Lemmatizer(column='text')),\n",
    "                         ('tfidf', TfidfVectorizer(sublinear_tf=True,\n",
    "                                                            strip_accents='unicode',\n",
    "                                                            analyzer='word',\n",
    "                                                            token_pattern=r'\\w{1,}',\n",
    "                                                            ngram_range=(1, 1),\n",
    "                                                            max_features=10000)),\n",
    "                         ('clf', RandomForestClassifier())])\n",
    "\n",
    "classifier_6 = Pipeline([('selector', FeatureSelector(column='text')),\n",
    "                         ('cleaner', Cleaner(column='text')),\n",
    "                         ('lemma', Lemmatizer(column='text')),\n",
    "                         ('tfidf', TfidfVectorizer(sublinear_tf=True,\n",
    "                                                            strip_accents='unicode',\n",
    "                                                            analyzer='word',\n",
    "                                                            token_pattern=r'\\w{1,}',\n",
    "                                                            ngram_range=(1, 1),\n",
    "                                                            max_features=10000)),\n",
    "                         ('clf', KNeighborsClassifier(n_neighbors=100))])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Разобьем данные на train/test с использованием стратификации"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.drop('label', 1),\n",
    "                                                    data['label'],\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=data['label'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Проверю баланс в обучащей и тестовой выборках"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "1    0.55509\n",
      "0    0.44491\n",
      "Name: label, dtype: float64\n",
      "Test:\n",
      "1    0.554982\n",
      "0    0.445018\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(f'Train:\\n{y_train.value_counts(normalize=True)}')\n",
    "print(f'Test:\\n{y_test.value_counts(normalize=True)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Запустим кросс-валидацию на 4-х фолдах\n",
    "В кач-ве метрики проверки качеcтва возьму площадь под кривой ROC"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB CV score is 0.8744349871627434\n",
      "SGDClassifier CV score is 0.8551020431852632\n",
      "LogisticRegression CV score is 0.8559135310199122\n",
      "RandomForestClassifier CV score is 0.8080429673190719\n",
      "KNeighborsClassifier CV score is 0.8216219867543592\n",
      "CPU times: user 2min 46s, sys: 3.97 s, total: 2min 50s\n",
      "Wall time: 2min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores_1 = cross_val_score(classifier_1, X_train, y_train, cv=4, scoring='roc_auc')\n",
    "cv_score_1 = np.mean(cv_scores_1)\n",
    "print('MultinomialNB CV score is {}'.format(cv_score_1))\n",
    "\n",
    "cv_scores_2 = cross_val_score(classifier_2, X_train, y_train, cv=4, scoring='roc_auc')\n",
    "cv_score_2 = np.mean(cv_scores_2)\n",
    "print('SGDClassifier CV score is {}'.format(cv_score_2))\n",
    "\n",
    "cv_scores_3 = cross_val_score(classifier_3, X_train, y_train, cv=4, scoring='roc_auc')\n",
    "cv_score_3 = np.mean(cv_scores_3)\n",
    "print('LogisticRegression CV score is {}'.format(cv_score_3))\n",
    "\n",
    "cv_scores_4 = cross_val_score(classifier_4, X_train, y_train, cv=4, scoring='roc_auc')\n",
    "cv_score_4 = np.mean(cv_scores_4)\n",
    "print('RandomForestClassifier CV score is {}'.format(cv_score_4))\n",
    "\n",
    "cv_scores_6 = cross_val_score(classifier_6, X_train, y_train, cv=4, scoring='roc_auc')\n",
    "cv_score_6 = np.mean(cv_scores_6)\n",
    "print('KNeighborsClassifier CV score is {}'.format(cv_score_6))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Удивительно, но без тонких настроек MultinomialNB дает самый лучший результат на кросс-валидации.\n",
    "Попробую подобрать порог для каждой модели и посмотрим на метрики.\n",
    "\n",
    "Для этого обучу все классификаторы и получу предикты"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57 s, sys: 1.5 s, total: 58.5 s\n",
      "Wall time: 57.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "classifier_1.fit(X_train, y_train)\n",
    "y_score_1 = classifier_1.predict_proba(X_test)[:, 1]\n",
    "\n",
    "classifier_2.fit(X_train, y_train)\n",
    "y_score_2 = classifier_2.predict_proba(X_test)[:, 1]\n",
    "\n",
    "classifier_3.fit(X_train, y_train)\n",
    "y_score_3 = classifier_3.predict_proba(X_test)[:, 1]\n",
    "\n",
    "classifier_4.fit(X_train, y_train)\n",
    "y_score_4 = classifier_4.predict_proba(X_test)[:, 1]\n",
    "\n",
    "classifier_6.fit(X_train, y_train)\n",
    "y_score_6 = classifier_6.predict_proba(X_test)[:, 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Найдем точность, полноту и порог для каждого классификатора\n",
    "precision_1, recall_1, threshold_1 = precision_recall_curve(y_test.values, y_score_1)\n",
    "precision_2, recall_2, threshold_2 = precision_recall_curve(y_test.values, y_score_2)\n",
    "precision_3, recall_3, threshold_3 = precision_recall_curve(y_test.values, y_score_3)\n",
    "precision_4, recall_4, threshold_4 = precision_recall_curve(y_test.values, y_score_4)\n",
    "precision_6, recall_6, threshold_6 = precision_recall_curve(y_test.values, y_score_6)\n",
    "\n",
    "# Найдем F-меру для каждого классификатора\n",
    "f_score_1 = (2*precision_1 * recall_1)/(precision_1 + recall_1)\n",
    "f_score_2 = (2*precision_2 * recall_2)/(precision_2 + recall_2)\n",
    "f_score_3 = (2*precision_3 * recall_3)/(precision_3 + recall_3)\n",
    "f_score_4 = (2*precision_4 * recall_4)/(precision_4 + recall_4)\n",
    "f_score_6 = (2*precision_6 * recall_6)/(precision_6 + recall_6)\n",
    "\n",
    "# Найдем индекс максимального значения F-меры. При этом эти же индексы будут принадлежать оптимальным значениям\n",
    "# точности, полноты и порога\n",
    "ix1 = np.argmax(f_score_1)\n",
    "ix2 = np.argmax(f_score_2)\n",
    "ix3 = np.argmax(f_score_3)\n",
    "ix4 = np.argmax(f_score_4)\n",
    "ix6 = np.argmax(f_score_6)\n",
    "\n",
    "roc_score_1 = roc_auc_score(y_test, y_score_1)\n",
    "roc_score_2 = roc_auc_score(y_test, y_score_2)\n",
    "roc_score_3 = roc_auc_score(y_test, y_score_3)\n",
    "roc_score_4 = roc_auc_score(y_test, y_score_4)\n",
    "roc_score_6 = roc_auc_score(y_test, y_score_6)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "                       F_score   ROC-AUC  Precision    Recall  Threshold\nMultinomialNB         0.837772  0.885679   0.780060  0.904707   0.472355\nSGDClassifier         0.821102  0.864438   0.745731  0.913422   0.459479\nLogReg                0.822509  0.867737   0.751201  0.908774   0.432340\nRFC                   0.794126  0.819029   0.734684  0.864033   0.441834\nKNeighborsClassifier  0.805728  0.839107   0.753030  0.866357   0.530000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>F_score</th>\n      <th>ROC-AUC</th>\n      <th>Precision</th>\n      <th>Recall</th>\n      <th>Threshold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>MultinomialNB</th>\n      <td>0.837772</td>\n      <td>0.885679</td>\n      <td>0.780060</td>\n      <td>0.904707</td>\n      <td>0.472355</td>\n    </tr>\n    <tr>\n      <th>SGDClassifier</th>\n      <td>0.821102</td>\n      <td>0.864438</td>\n      <td>0.745731</td>\n      <td>0.913422</td>\n      <td>0.459479</td>\n    </tr>\n    <tr>\n      <th>LogReg</th>\n      <td>0.822509</td>\n      <td>0.867737</td>\n      <td>0.751201</td>\n      <td>0.908774</td>\n      <td>0.432340</td>\n    </tr>\n    <tr>\n      <th>RFC</th>\n      <td>0.794126</td>\n      <td>0.819029</td>\n      <td>0.734684</td>\n      <td>0.864033</td>\n      <td>0.441834</td>\n    </tr>\n    <tr>\n      <th>KNeighborsClassifier</th>\n      <td>0.805728</td>\n      <td>0.839107</td>\n      <td>0.753030</td>\n      <td>0.866357</td>\n      <td>0.530000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data = [[f_score_1[ix1],roc_score_1,precision_1[ix1],recall_1[ix1],threshold_1[ix1]],\n",
    "                    [f_score_2[ix2],roc_score_2, precision_2[ix2],recall_2[ix2],threshold_2[ix2]],\n",
    "                    [f_score_3[ix3],roc_score_3,precision_3[ix3],recall_3[ix3],threshold_3[ix3]],\n",
    "                    [f_score_4[ix4],roc_score_4,precision_4[ix4],recall_4[ix4],threshold_4[ix4]],\n",
    "                    [f_score_6[ix6],roc_score_6,precision_6[ix6],recall_6[ix6],threshold_6[ix6]]],\n",
    "            index = ['MultinomialNB','SGDClassifier','LogReg','RFC','KNeighborsClassifier'],\n",
    "            columns = ['F_score','ROC-AUC','Precision','Recall','Threshold'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "По соотноению сложности и эффективности MultinomialNB выигрывает.\n",
    "\n",
    "Зная как он работает, могу предположить, что для решения конкретной задачи связь между словами(с которой алгоритм работает плохо)\n",
    "не так важна. Возможно так оно и есть - сленговые слова тематики программирования встречаются в обоих классах,\n",
    "но в чатике DS встречаются слова с сильным уклоном в математику/сленговые выражения DS,\n",
    "что явно свидетельствует о принадлежности к данному классу.\n",
    "\n",
    "Странно, думал это будет SGD, но имеем что имеем.\n",
    "Попробуем улучшить алгоритм путем подбора параметров по сетке.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-24-72f40f3017e4>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m }\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mGridSearchCV\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mclassifier_1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mparameters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcv\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'Best score and parameter combination:\\n{model.best_score_, model.best_params_}'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/nlp_classification/venv/lib/python3.6/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m             \u001B[0;31m# extra_args > 0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/nlp_classification/venv/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    839\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    840\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 841\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_run_search\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    842\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    843\u001B[0m             \u001B[0;31m# multimetric is determined here because in the case of a callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/nlp_classification/venv/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36m_run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m   1294\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_run_search\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1295\u001B[0m         \u001B[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1296\u001B[0;31m         \u001B[0mevaluate_candidates\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mParameterGrid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparam_grid\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1297\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1298\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/nlp_classification/venv/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001B[0m in \u001B[0;36mevaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    807\u001B[0m                                    (split_idx, (train, test)) in product(\n\u001B[1;32m    808\u001B[0m                                    \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcandidate_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 809\u001B[0;31m                                    enumerate(cv.split(X, y, groups))))\n\u001B[0m\u001B[1;32m    810\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    811\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/nlp_classification/venv/lib/python3.6/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1052\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1053\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mretrieval_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1054\u001B[0;31m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mretrieve\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1055\u001B[0m             \u001B[0;31m# Make sure that we get a last message telling us we are done\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1056\u001B[0m             \u001B[0melapsed_time\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtime\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtime\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_start_time\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/nlp_classification/venv/lib/python3.6/site-packages/joblib/parallel.py\u001B[0m in \u001B[0;36mretrieve\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    931\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    932\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mgetattr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m'supports_timeout'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 933\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    934\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    935\u001B[0m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_output\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mextend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mjob\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/nlp_classification/venv/lib/python3.6/site-packages/joblib/_parallel_backends.py\u001B[0m in \u001B[0;36mwrap_future_result\u001B[0;34m(future, timeout)\u001B[0m\n\u001B[1;32m    540\u001B[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001B[1;32m    541\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 542\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfuture\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    543\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mCfTimeoutError\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    544\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mTimeoutError\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.6/concurrent/futures/_base.py\u001B[0m in \u001B[0;36mresult\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    425\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__get_result\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    426\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 427\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_condition\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    428\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    429\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_state\u001B[0m \u001B[0;32min\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mCANCELLED\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mCANCELLED_AND_NOTIFIED\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/lib/python3.6/threading.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    293\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m    \u001B[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    294\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 295\u001B[0;31m                 \u001B[0mwaiter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    296\u001B[0m                 \u001B[0mgotit\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    297\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "parameters = {\n",
    "    'clf__alpha':[0, 0.01, 0.1, 0.5, 1.2],\n",
    "    'clf__fit_prior': [True, False],\n",
    "    'tfidf__strip_accents':['ascii', 'unicode', None],\n",
    "    'tfidf__ngram_range':[(1,1), (2,3), (3,4)]\n",
    "}\n",
    "\n",
    "model = GridSearchCV(classifier_1, parameters, cv=4, n_jobs=-1).fit(X_train, y_train)\n",
    "\n",
    "print(f'Best score and parameter combination:\\n{model.best_score_, model.best_params_}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Построй облако слов для наглядности\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}